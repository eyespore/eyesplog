{"./":{"url":"./","title":"站点介绍","keywords":"","body":" 欢迎！ 这里是Pineclone的文档站点，他会把笔记推送到这里。 edit by qqaLast edited on: 2024-09-07 13:24:57 "},"note/program_language/":{"url":"note/program_language/","title":"编程语言","keywords":"","body":"编程语言 edit by qqaLast edited on: 2024-09-04 15:30:29 "},"note/program_language/java/":{"url":"note/program_language/java/","title":"Java","keywords":"","body":"Java 命名规范 项目名： Java项目名全部采用小写字母，多个单词时采用中划线-来进行分隔 例如：my-java-project 包名： 包名也采用小写字母，使用点.作为单词分隔符，包名通常由项目发起人、项目名、模块名等部分组成，具体取决于公司命名策略 例如：com.example.project 类名： 采用大驼峰书写 例如：HelloWorld.java 变量名： 采用小驼峰书写 例如：fileContext 常量名： 全大写，使用下划线分隔单词 例如：STATIC_VALUE edit by qqaLast edited on: 2024-09-07 13:24:57 "},"note/program_language/java/third_party_lib/":{"url":"note/program_language/java/third_party_lib/","title":"第三方库","keywords":"","body":"常用第三方库 edit by qqaLast edited on: 2024-09-07 13:24:57 "},"note/program_language/java/third_party_lib/apache_poi.html":{"url":"note/program_language/java/third_party_lib/apache_poi.html","title":"Apache POI","keywords":"","body":"Apache POI Apache POI是一个用Java编写的免费开源的跨平台Java API，全称“Poor Obfuscation Implementation”，意为“简洁版的模糊实现”。Apache POI提供了一套丰富的API给Java程序，使其能够读写Microsoft Office格式的文件，包括但不限于Excel（.xls和.xlsx）、Word（.doc和.docx）、PowerPoint（.ppt和.pptx）等 Apache POI提供了一系列IO接口，来让用户操作文档： 写：通过写操作，可以将数据写入Mircrosoft文件中，例如Excel 读：通过读操作，可以将需要信息通过共享的形式让用户录入Excel表格中，之后通过Apache POI读取数据，将数据转换成为对象之后，存储到数据库当中 常见的应用场景： 银行系统导出交易明细 业务系统导出Excel报表 批量导入业务数据 maven项目通过maven坐标导入Apache POI依赖，从而在项目中使用Apache POI： org.apache.poi poi 3.9 org.apache.poi poi-ooxml 3.9 Excel IO 写单元格 Apache POI操作Excel文件代码具有良好的可读性，其API根据手写Excel文件的体验设计 Excel文件具有如下格式： Excel当中会包含若干行列，它们被分布在一个sheet中 一份Excel文档中可以创建多个sheet 用户对某一张sheet中的单元格进行具体的操作 Apache POI的写操作类似这样的过程，示例代码如下： @Test public void testWrite() throws Exception{ XSSFWorkbook excel = new XSSFWorkbook(); // 创建excel XSSFSheet sheet1 = excel.createSheet(\"sheet1\"); // 创建sheet，命名为sheet1 XSSFRow row = sheet1.createRow(0); // 创建第一行，注意第一行索引为0 row.createCell(0).setCellValue(\"id\"); row.createCell(1).setCellValue(\"username\"); row.createCell(2).setCellValue(\"password\"); row = sheet1.createRow(1); // 创建第二行，并且往三个单元格插入数据 row.createCell(0).setCellValue(\"1\"); row.createCell(1).setCellValue(\"qqa\"); row.createCell(2).setCellValue(\"1234aaa\"); // 导出文件 FileOutputStream fos = new FileOutputStream(\"D:\\\\desktop\\\\info.xlsx\"); excel.write(fos); excel.close(); // 关闭资源 fos.close(); } 通过文件输出流会在桌面下自动生成excel文件，效果如下： 在写操作中，我们遵循下面的流程： 创建一个excel文件对象 通过对象创建一个row，接着创建一个cell 然后就能够对单元格cell进行操作了 读单元格 Apache POI读操作，通过文件输入流，将Excel文件读取进入Apache POI的excel表格对象中，示例代码如下： @Test public void testRead() throws Exception { // 创建一个文件输入流，用于读取excel文件 FileInputStream fis = new FileInputStream(\"D:\\\\desktop\\\\info.xlsx\"); // 创建excel操作对象，使用前面的文件输入流来初始化它 XSSFWorkbook excel = new XSSFWorkbook(fis); XSSFSheet sheet = excel.getSheet(\"sheet1\"); // 通过getLastRow方法可以获取存在内容的最后一行的行号 int last = sheet.getLastRowNum(); // 这里获取的是索引，所以应该是1 // for循环直接从1开始，因为第一行为表头 for (int i = 1; i 遍历通过sheet对象的getLastRow方法获取最大行索引，然后进行遍历，执行结果： edit by qqaLast edited on: 2024-09-07 13:24:57 "},"note/program_language/java/third_party_lib/mybatis.html":{"url":"note/program_language/java/third_party_lib/mybatis.html","title":"Mybatis","keywords":"","body":"Mybatis 中文官方网站：https://mybatis.net.cn/，点评是十分易读好懂 快速开始 MVC框架中作为持久层存在，也可以单独用于操作数据库，与传统ORM持久层框架不同，Mybatis采用基于Mapper映射器的关系，简化对数据库的CRUD操作 在项目中引入依赖： org.mybatis mybatis 3.5.14 mysql mysql-connector-java 8.0.30 org.projectlombok lombok 1.18.26 mybatis需要进行正确的配置才能使用，其中包括： 数据库连接信息 事务管理器 指定包扫描，从而构建mapper 返回对象的别名等信息 习惯性地，一般直接在resources目录下创建一份名为mybatis-config.xml的配置文件和一份名为jdbc.properties的数据库连接信息配置文件 也可以直接将连接信息写在mybatis-config.xml当中，只是这种分文件的写法要更灵活一些 mybatis-config-xml： jdbc.properties： jdbc.url=jdbc:mysql://localhost:3306/database1?useSSL=false jdbc.username=root jdbc.password=1234 jdbc.driver=com.mysql.cj.jdbc.Driver 编写pojo：以下仅仅为示例，按照项目需求编写即可 club.pineclone.pojo.User.java @Data @NoArgsConstructor @AllArgsConstructor public class User { private Integer id; private String username; private String password; } 编写mapper映射器：sql可以是配置文件形式、也可以是注解形式，通常前者用于复杂场景，后者用于简单场景： 配置形式： club.pineclone.mapper.UserMapper.java： public interface UserMapper { List selectAll(); } club/pineclone/mapper/UserMapper.xml （注：mapper配置文件需要和类有同样的层级结构才能构成映射关系） select * from user 注解形式： public interface UserMapper { @Select(\"select * from user\") List selectAll(); } mybaits的核心在于SqlSessionFactory提供的API，因此首先需要构建SqlSessionFactory： String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); 通过sqlSessionFactory获得mapper对象来执行方法操作数据库 SqlSession session = sqlSessionFactory.openSession(); UserMapper mapper = session.getMapper(UserMapper.class); System.out.println(mapper.selectAll()); session.commit(); // 默认开启事务 session.close(); // 关闭资源 CRUD 简单SQL 简单SQL可以直接使用注解形式书写： @Insert(\"insert into users(name, age) VALUES (#{user.name}, #{user.age}\") int insertUser(Users user); @Delete(\"delete from users where id = #{id}\") int deleteById(Long id); @Select(\"select name, age from users where id = #{id}\") User selectById(Long id); @Update(\"update users set name = #{name} where id = #{id}\") int updateById(User user); 复杂SQL 复杂SQL建议使用mapper.xml的形式进行配置，合理利用MyBatis提供的动态 SQL（Dynamic SQL）来编写复杂的SQL指令 插入 批量插入： insert into dish_flavor(dish_id, name, value) values (#{flavor.dishId}, #{flavor.name}, #{flavor.value}) 插入后返回主键： insert into users (name, age) values (#{name}, #{age}) 删除 批量删除： delete from dish_flavor where dish_id in #{dishId} 修改 条件插入： update category type = #{type}, name = #{name}, sort = #{sort}, status = #{status}, update_time = #{updateTime}, update_user = #{updateUser} where id = #{id} 仅仅在值存在的情况下执行更新操作 查询 条件查询： select * from category and name like concat('%',#{name},'%') and type = #{type} order by sort asc , create_time desc 按照sort列进行升序排列，若sort字段值相同，则按create_time的值降序排列 连接查询： select d.*, c.`name` as `categoryName` from dish d left join category c on d.category_id = c.id and d.name like concat('%', #{name} ,'%') and d.category_id = #{categoryId} and d.status = #{status} order by d.create_time desc 注意事项 关于#{}和${}占位符 ${}：用于直接文本替换，不会进行参数的转义或类型检查，存在 SQL 注入风险，适用于动态 SQL 构建场景，如表名或列名的动态设置，例如： SELECT * FROM ${tableName} WHERE ${columnName} = 'some_value'; #{}：用于安全地传递参数，MyBatis 会对参数进行预编译处理，避免 SQL 注入，适用于大多数传递参数的场景，如查询条件或插入数据，例如： SELECT * FROM users WHERE username = #{username}; 更换数据源 作为ORM框架，mybatis通过与数据库建立连接来工作，通常情况下，当dataSource标签的type属性值为POOLED时，mybatis使用其内置的连接池来管理连接 在实际中，我们会倾向于选择提供了更好的性能优化、监控管理能力、多数据库支持的数据源，而mybaits内置的数据源往往不能满足需求，此时需要更换为第三方数据源，常用第三方数据源如下： DBCP C3P0 Druid：性能也比较好，提供了比较便捷的监控系统 Hikari：性能最好 druid 将mybaits数据源切换为druid，为项目引入druid依赖： com.alibaba druid 1.2.1 参考mybaits的配置文件中对datasource的配置： 我们通过type来指定类名，但是由于mybatis要求这里必须是DataSourceFacotry的实现类，因此这里不能直接指定com.alibaba.pool.DruidDataSource 可以手动创建一个实现类，让它返回DruidDataSource即可： public class DruidDataSourceFactory implements DataSourceFactory { @Override public void setProperties(Properties props) {} @Override public DataSource getDataSource() { DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(\"jdbc:mysql://127.0.0.1:3306/pineclone?useSSL=false\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"1234\"); dataSource.setDriverClassName(\"com.mysql.jdbc.Driver\"); return dataSource; } } 当然，和数据源相关的配置也可以一并在此处配置好，大可以将mybatis-config.xml当中的配置给注释掉： --> --> --> --> 不过使用什么样的手法来配置DruidDataSource是自由的，并不拘泥于这种方式，您也许注意到了上面DataSourceFactory接口的setProperties方法，它同样能用于配置参数 edit by qqaLast edited on: 2024-09-07 13:24:57 "},"note/program_language/java/third_party_lib/logback.html":{"url":"note/program_language/java/third_party_lib/logback.html","title":"Logback","keywords":"","body":"Logback 官方文档： http://logback.qos.ch/manual/index.html 参考：https://www.cnblogs.com/simpleito/p/15133654.html Java开源日志框架，以继承改善log4j为目的，是log4j创始人Ceki Gülcü的开源产品。声称有极佳的性能，占用空间更小，且提供其他日志系统缺失但很有用的特性。其一大特色是，在 logback-classic 中本地(native)实现了 SLF4J API（也表示依赖 slf4j-api） logback-core：其他俩模块基础模块，作为通用模块 其中没有 logger 的概念 logback-classic：日志模块，完整实现了 SLF4J API logback-access：配合Servlet容器，提供 http 访问日志功能 edit by qqaLast edited on: 2024-09-07 13:24:57 "},"note/optional_system/":{"url":"note/optional_system/","title":"操作系统","keywords":"","body":"操作系统 edit by qqaLast edited on: 2024-09-04 15:30:29 "},"note/optional_system/vitualize/":{"url":"note/optional_system/vitualize/","title":"虚拟化","keywords":"","body":"虚拟化 edit by qqaLast edited on: 2024-09-04 15:30:29 "},"note/optional_system/vitualize/docker/":{"url":"note/optional_system/vitualize/docker/","title":"Docker","keywords":"","body":" Docker edit by qqaLast edited on: 2024-09-04 16:05:12 "},"note/optional_system/vitualize/docker/docker_basic.html":{"url":"note/optional_system/vitualize/docker/docker_basic.html","title":"Docker基础","keywords":"","body":"Docker基础 edit by qqaLast edited on: 2024-09-04 15:30:29 "},"note/optional_system/vitualize/docker/service_deploy/":{"url":"note/optional_system/vitualize/docker/service_deploy/","title":"服务部署","keywords":"","body":"edit by qqaLast edited on: 2024-09-07 13:24:57 "},"note/optional_system/vitualize/docker/service_deploy/docker_mysql.html":{"url":"note/optional_system/vitualize/docker/service_deploy/docker_mysql.html","title":"Mysql","keywords":"","body":"Mysql 通过docker-compose.yml部署：在用户根目录下创建mysql根目录并且创建compose文件： mkdir -p ~/mysql/data && echo \"\" > ~/mysql/compose.yml && vim ~/mysql/compose.yml 定义三个挂载卷，对容器的数据、配置、日志进行持久化存储 version: '3.8' services: db: container_name: mysql hostname: mysql image: mysql:9.0 restart: always environment: MYSQL_ROOT_PASSWORD: 1234 ports: - 3306:3306 volumes: - ./data:/var/lib/mysql - ./conf:/etc/mysql/mysql.conf.d - ./logs:/logs healthcheck: test: [ \"CMD\", \"mysqladmin\" ,\"ping\", \"-h\", \"localhost\" ] interval: 5s timeout: 10s retries: 10 docker compose up -d 关于数据迁移： 主要是将docker容器形式的mysql数据库当中的数据迁移，mysql内置了将数据库、表、数据转换成为.sql文件的功能，通过转移.sql文件，将数据重新部署到新的mysql数据库上面，操作步骤： docker exec -it mysql /bin/bash # 进入mysql容器 docker compose exec mysql /bin/bash # compose形式 进入mysql数据所在的目录， cd /var/lib/mysql/ 这个目录下构建数据对应的sql文件，如果/var/lib/mysql已经被挂载到容器外，那么保存之后就可以在外部将数据文件进行传输 通过ls命令来查看有哪些数据需要保存，数据文件和数据库名相同： 这里保存pineclone_data到.sql文件，执行命令： mysqldump -uroot -p pineclone_data > pineclone_data.sql 然后键入管理员命令，即可在当前目录生成数据sql文件，将这份文件迁移到新的数据库当中执行即可 导入数据到新的数据库之前，数据库本身还是要自己建立的 edit by qqaLast edited on: 2024-09-07 13:24:57 "}}